"""
Example usage of Anonymous LinkedIn Scraper
Demonstrates various scraping scenarios without login
"""
import asyncio
import os
from anonymous_linkedin_scraper import AnonymousLinkedInScraper
from proxy_manager import setup_proxy_rotation


async def example_basic_scraping():
    """Basic anonymous scraping example"""
    print("üîπ Example 1: Basic Anonymous Scraping")
    print("=" * 50)
    
    # Set basic configuration
    os.environ['SEARCH_KEYWORDS'] = 'python programming,data science'
    os.environ['MAX_POSTS'] = '20'
    os.environ['HEADLESS'] = 'True'
    os.environ['STEALTH_MODE'] = 'True'
    
    scraper = AnonymousLinkedInScraper()
    await scraper.main()
    
    print(f"‚úÖ Scraped {len(scraper.scraped_posts)} posts")
    return scraper.scraped_posts


async def example_with_proxies():
    """Example with proxy rotation"""
    print("\nüîπ Example 2: Scraping with Proxy Rotation")
    print("=" * 50)
    
    # First, set up proxy rotation
    working_proxies = await setup_proxy_rotation()
    
    if working_proxies:
        # Configure scraper with proxies
        os.environ['USE_PROXIES'] = 'True'
        os.environ['PROXY_LIST'] = ','.join(working_proxies[:5])  # Use top 5
        os.environ['SEARCH_KEYWORDS'] = 'machine learning,AI'
        os.environ['MAX_POSTS'] = '15'
        
        scraper = AnonymousLinkedInScraper()
        await scraper.main()
        
        print(f"‚úÖ Scraped {len(scraper.scraped_posts)} posts using proxies")
    else:
        print("‚ùå No working proxies available, skipping proxy example")


async def example_stealth_mode():
    """Example with maximum stealth features"""
    print("\nüîπ Example 3: Maximum Stealth Scraping")
    print("=" * 50)
    
    # Configure for maximum stealth
    os.environ['HEADLESS'] = 'True'
    os.environ['STEALTH_MODE'] = 'True'
    os.environ['DELAY_MIN'] = '5'
    os.environ['DELAY_MAX'] = '12'
    os.environ['MAX_POSTS'] = '10'
    os.environ['SEARCH_KEYWORDS'] = 'software engineering'
    
    scraper = AnonymousLinkedInScraper()
    await scraper.main()
    
    print(f"‚úÖ Stealth scraped {len(scraper.scraped_posts)} posts")


async def example_trending_content():
    """Example scraping trending content without specific keywords"""
    print("\nüîπ Example 4: Scraping Trending Content")
    print("=" * 50)
    
    # No search keywords = trending content
    os.environ['SEARCH_KEYWORDS'] = ''
    os.environ['MAX_POSTS'] = '25'
    os.environ['HEADLESS'] = 'False'  # Show browser for demo
    
    scraper = AnonymousLinkedInScraper()
    await scraper.main()
    
    print(f"‚úÖ Scraped {len(scraper.scraped_posts)} trending posts")


async def example_high_volume_scraping():
    """Example for scraping larger volumes of data"""
    print("\nüîπ Example 5: High-Volume Scraping")
    print("=" * 50)
    
    # Configure for high-volume scraping
    os.environ['SEARCH_KEYWORDS'] = 'technology,innovation,startup'
    os.environ['MAX_POSTS'] = '100'
    os.environ['HEADLESS'] = 'True'
    os.environ['DELAY_MIN'] = '2'
    os.environ['DELAY_MAX'] = '5'
    os.environ['CSV_FILENAME'] = 'high_volume_posts.csv'
    
    scraper = AnonymousLinkedInScraper()
    await scraper.main()
    
    print(f"‚úÖ High-volume scraped {len(scraper.scraped_posts)} posts")


def print_scraping_tips():
    """Print tips for effective anonymous scraping"""
    print("\nüìã Anonymous LinkedIn Scraping Tips:")
    print("=" * 50)
    print("‚úÖ DO:")
    print("  ‚Ä¢ Use reasonable delays between requests (3-8 seconds)")
    print("  ‚Ä¢ Rotate user agents automatically")
    print("  ‚Ä¢ Save and reuse cookies")
    print("  ‚Ä¢ Use headless mode for production")
    print("  ‚Ä¢ Monitor rate limits")
    print("  ‚Ä¢ Scrape during off-peak hours")
    print("  ‚Ä¢ Use proxy rotation for large volumes")
    print("  ‚Ä¢ Respect robots.txt")
    
    print("\n‚ùå DON'T:")
    print("  ‚Ä¢ Make too many concurrent requests")
    print("  ‚Ä¢ Use the same IP for extended periods")
    print("  ‚Ä¢ Ignore rate limits")
    print("  ‚Ä¢ Scrape personal/private data")
    print("  ‚Ä¢ Violate terms of service")
    print("  ‚Ä¢ Use for commercial purposes without permission")
    
    print("\nüîß Configuration Tips:")
    print("  ‚Ä¢ Start with small batches (10-20 posts)")
    print("  ‚Ä¢ Test with headless=False first")
    print("  ‚Ä¢ Use stealth mode for better success rates")
    print("  ‚Ä¢ Save cookies between sessions")
    print("  ‚Ä¢ Monitor response times and errors")


async def main():
    """Run all examples"""
    print("üöÄ Anonymous LinkedIn Scraper Examples")
    print("=" * 60)
    print("‚ö†Ô∏è LEGAL NOTICE: These examples scrape only public data.")
    print("   Please respect LinkedIn's Terms of Service.")
    print("=" * 60)
    
    # Print tips first
    print_scraping_tips()
    
    # Ask user which example to run
    print("\nAvailable examples:")
    print("1. Basic anonymous scraping")
    print("2. Scraping with proxy rotation") 
    print("3. Maximum stealth scraping")
    print("4. Trending content scraping")
    print("5. High-volume scraping")
    print("6. Run all examples")
    
    choice = input("\nSelect example (1-6): ").strip()
    
    try:
        if choice == "1":
            await example_basic_scraping()
        elif choice == "2":
            await example_with_proxies()
        elif choice == "3":
            await example_stealth_mode()
        elif choice == "4":
            await example_trending_content()
        elif choice == "5":
            await example_high_volume_scraping()
        elif choice == "6":
            print("üîÑ Running all examples...")
            await example_basic_scraping()
            await example_stealth_mode()
            await example_trending_content()
        else:
            print("Invalid choice. Running basic example...")
            await example_basic_scraping()
            
    except KeyboardInterrupt:
        print("\nüëã Examples stopped by user")
    except Exception as e:
        print(f"\n‚ùå Error running examples: {str(e)}")


if __name__ == "__main__":
    asyncio.run(main())
